---
layout: post
title: Consciousness is not computation
date: 2022-02-19
categories: ml
image:
  feature: constellations3.jpg
---

It's a common article of faith in the tech world that computers will one day
gain consciousness.  With big enough computers and sophisticated enough AI, the
reasoning goes, it is inevitable that sooner or later computers will become
conscious just as we are.  In fact, some have made the bolder claim that this
isn't merely something that will happen in the distant future future, but that
this day is upon us already.  [TODO] famously argued that essentially any
feedback system, even one as simple as a thermostat, is conscious, even if in a
limited way.  Recently AI researcher Ilya Sutskever speculated that today's
neural networks may be conscious.

But this idea is wrong.  Computation alone is insufficient to produce
consciousness.


This position started to gain some currency among philosophers who studied
philosophy of mind back in the 1960s and 1970s as the [TODO funnctionalism?] .
As general purpose computers were being developed and the theory behind
computer science , and was clear that a new paradigm was emerging.  Explaining
conciousness had been one of the thorniest problems of philosophy since the
time of Descartes --- could this radical new paradigm of computation explain
it?  the idea is But a trio of three counter-arguments around the same time.  Philosophy moves fairly slowly, but I
think it's safe to say that today, 50 years on, the position that consciousness
is computation is not widely held.


The argument that consciousness is not computation [TODO footnote note that
computation may be *necessary*, but it cannot be sufficient] has two parts.
The first is that  [qualia exists] .  The second half is that computation
cannot produce these feelings.

* Qualia is distinct [What Mary Knows]
* System 

So why is it that 


## Some preliminaries

### What I mean by "consciousness"

Before getting too deep we need a working definition of consciousness.  This is
one of the thorniest concepts to define rigorously since it seems that a
rigorous definition of consciousness practically requires a theory of
consciousness itself.  To make matters worse, in these kinds of discussions it
oftentimes gets mingled with related ideas of self-awareness and intelligence.
But in this post I am interested only in consciousness as a sort of perception
--- an awareness of being, or, more loosely, "what it feels like to be
something."

This aspect of consciousness is sometimes called "qualia." [^1] The classic
argument that qualia can't be ignored is due to Frank Jackson in the article
"What Mary Didn't Know."  I encourage you to read the original article (and the
Wikipedia article), but in brief, the argument proposes a thought experiment:
Suppose there is a scientist named Mary.  Through extensive study, she has
learned all there is to know about the physics of color, the physiology of the
eye, and the neurology of the brain.  Given some stimulus like looking at a red
rose, she knows exactly how the light impacts the eye, how the image forms on
the retina, how this produces a signal along the optical nerve, and how the
brain processes this signal.  However, Mary has lived her entire life within a
black and white room and has never perceived color herself.  One day, she
leaves the room and looks at a red rose.  Does she learn anything new from this
experience?  If she does, we are forced to conclude that qualia exists --- that
an experience is distinct from perfect knowledge of how the brain reacts to the
stimuli that produced that experience.

But if we accept that qualia exists (which, after all, seems intuitively
sensible), we are burdened with the apparently impossible task of explaining
how consciousness is generated by physical processes.

#### Consciousness is observer independent

It's worth pausing here and noting one useful property of consciousness.
Consciousness is independent of external observers.  By this I mean that my
consciousness does not depend on other observers perceiving me to be conscious.
Even if all other conscious beings in the universe should deny that I am
conscious --- or if those other observers did not exist at all --- this would
have no bearing on my own consciousness.

### What is computation?

Next we need a working definition of computation.  Fortunately this is an idea
that is much less fuzzy than consciousness.  Computation, in the broadest
sense, is the manipulation of symbols according to an algorithm.  The largest
and most important category of computation are those algorithms which can, in
principle, be run on a Turing machine.  As far as we know, every algorithm that
can be run on a physical computer can also be run on a Turing machine (and the
statement that this is necessarily true is known as the Church-Turing Thesis).
[^2]

#### What is a computer?

This then brings us to the companion question of what exatly constitutes a
computer.  Now, a Turing machine is a purely mathematical abstraction, like a
circle or a logarithm.  We can manifast things in the real world which can be
well modeled by a circle, but the abstract idea of a circle is distinct from a
drawing of a circle.

Likewise we can build an object in the real world which can model the behavior
of the abstract Turing machine.  And, more practically, we can build devices
whose behavior, while not identical to that of a Turing machine, can compute
the same things as some Turing machine.  We call such devices computers.

At this stage we have to ask how accurate the computer has to be to still be
called a computer.  After all, any physical manifestation of a Turing machine
will be an approximation of the abstract concept, just as any drawing of a
circle won't be exactly circular.  Sometimes the computer will make a mistake
--- a cosmic ray will fly through and flip a bit for example. [^3]  If we
decide that a machine is not a computer simply because it ever makes *any*
errors, we will have to conclude that consciousness is not computation for the
simple reason that there are no computers.

A more reasonable definition of a computer is that it is a machine which
produces outputs which correspond to those of an ideal Turing machine's given
the same inputs. [^4]  If it makes a mistake somewhere and breaks that
correspondance, then it stops being a computer for the time being, or at least
a computer corresponding to that particular Turing machine.  This is a useful
definition because it abstracts away the internal physical workings of the
computer.  The computer can use transistors or vacuum tubes or something else
entirely, and we can just focus on what the abstract Turing machine is doing.

## Consciousness in a field of rocks

Since computation is independent of the physical mechanism, we can imagine
(impractical) computers that are made out of things other than electronics.  We
can create mechanical computers out of balls rolling around networks of tubes.
XKCD imagined the limit of this principle, an individual in a vast desert
filled with rocks who manipulates them to produce a computer and simulate the
entire universe.

And, indeed, .

So let's suppose that it is possible to generate consciousness by running a
sufficiently clever computer program (call it `consciousness.py`) on a
sufficiently large computer.  Then it must also be possible to manipulate a
large enough number of rocks on a desert to run the same program and generate
the same consciousness.

One of my favorite XKCD cartoons is #505.  It imagines an individual who finds
himself in a vast desert filled with rocks where time and space are infinite.
To allay his boredom, he derives all the laws of physics and then begins to lay
out the rocks and use them as a computer.  In this infinite desert, instant by
instant, he simulates the entire universe.


### Can a computer make mistakes and still be conscious?

The cartoon also imagines that sometimes this individual makes a mistake in his
simulation.  He misplaces a rock and in his simulated universe a mote of dust
disappears.  Let's consider this idea a bit more closely and think about what
happens if a computer ran the `consciousness.py` program but the computer
sometimes made mistakes.

This isn't a hypothetical question.  Cosmic rays cause errors in modern digital
computers more frequently than many people realize. [TODO footnote about how
you can use your smartphone as a cosmic ray detector]  One position we could
take is that a computer can only produce consciousness if it is 100%
deterministic, i.e., there is no possibility of error in its computations.
This seems to me to preclude any real computer from ever being conscious since
any physical computer in the real world will have some chance of error, even if
it is small.  And surely if the error rate is very small and you run the
program and get lucky and no errors *actually* occur, this should be just as
good as running a theoretical computer that is 100% accurate.

This allows us to establish the following proposition: Assume that a computer
with a 0% error rate runs a program that produces consciousness.  Now run the
same program on a computer with a non-zero error rate.  If, on a particular
run, that computer happens to produce the same outputs and intermediate steps
as the perfect computer, then the imperfect computer has also produced
consciousness.

## Does iron become conscious when it's hot?

Now it already seems implausible to me that a vast desert of rocks being
manipulated into various patterns is conscious.  Nevertheless this argument
doesn't convince everybody.  Some believe that while it might be hard to
imagine what it means for this vast desert of rocks to be conscious, there are
lots of inuintuitive things in this world.  We shouldn't let our prejudices as
to what substrate consciousness *should* exist in prevent us from accepting
that it could very well exist in a substrate which is unfamiliar to us. [^5]

But I would like to take this argument and follow it to its logical conclusion.
If we accept that consciousness is computation, then we are forced to conclude
that a hot bar of iron is conscious.

Let's imagine a bar of iron heated past the Curie temperature.  Each atom in
the bar has a magnetic moment which points either up or down.  For simplicity,
let's assume that the bar is very hot and that the magnetic moment of each atom
is randomly flipping between up and down.  Moreover we have the means to
observe whether the magnetic moment of every atom in the bar is up or down at
any given time.

I want to determine if this bar of iron is consciousness, so I examine its
atoms to see if it is running `consciousness.py`.  I designate the first $N$
atoms to be input bits, another $N$ atoms to be internal states of the Turing
machine, and then another $N$ atoms to be outputs.  Then I look at the magnetic
moments of those atoms sampled at different time steps and see if they
correspond to the inputs, outputs, and intermediate states of
`consciousness.py` by designating a moment pointing "up" as a 1 and a moment
pointing "down" as a 0.  Naturally, there is no correspondance so I conclude
that the bar of iron is not conscious.

Simultaneously, however, my friend Alice performs the same observation.
But rather than designating atoms pointing "up" as a 1 and a moment pointing
down as a 0, she does the opposite.  Naturally, she, too, observes no
correspondance with `consciousness.py` and concludes that the bar of iron is
not conscious.

But another friend of mine, Bob, makes the same observation, but uses a
slightly different encoding.  He considers an atom pointing up to be a 1,
unless it's the first atom in the bar, in which case it's a 0.  Simiarly Carl
performs the same observation, but in his encoding, an atom pointing up is a 1
unless it's the second atom, and so on.  Eventually we get to Ada, who encodes
an atom pointing up as a 1 unless it's the first or second in which case it's
a 0.  Then Barbara, who encodes an atom pointing up as a 1 unless it's the
first or third.

Now we can imagine an enormous crowd of observers staring at this iron bar,
each using a unique encoding of atom states to bits.  With a sufficiently large
number of observers, one of them will, by chance, happen to observe that the
states of the atoms correspond exactly to the bits of a Turing machine
computing `consciousness.py`.  This observer will then conclude that the bar of
iron is a computer running `consciousness.py` and is therefore concsious.

But if a single observer can correctly determine that the bar of iron is
conscious, we must conclude that the bar of iron is conscious for *everybody*,
because concsiousness is observer independent.  Because this lucky observer
exists, if concsiousness is just a matter of running `consciousness.py`, we
must conclude that the bar of iron *really is conscious*.

To make matters worse, I have not specified what `consciousness.py` is.  There
are many possible `consciousness.py` programs --- some corresponding to you and
me --- and this bar of iron is running *all of them*.  So not only is the bar
of iron conscious, it contains *all possible consciousnesses.*

And of course there's nothing special about the iron itself.  We could make the
same argumetn with a large number of coin tosses or the locations of atoms in
the air of a room.  In all cases we are forced to conclude that a sufficiently
large system contains all possible consciousnesses.  So the proposition that
consciousness is computation leads quite inextricably to a sort of
pan-consciousness.


We can imagine an arbitrary number of observers, each with their own unique
definition of how the spins of the atoms in this bar map onto bits of their
Turing machine.  In fact, let's assume that there is .  This is, of course, a
physically absurd scenario, but the joy of philosophical thought experiments is
that you can devise them without any regard to physical impracticality.  We can
imagine a universe with .

One of these observers will happen to have an encoding which happens to match
the observed fluctuations of the magnetic moments of the iron atoms in the bar.
This observer will see that a Turing machine has successfully computed the
`consciousness.py` program with all outputs and intermediate steps matching the
output of a theoretically perfect Turing machine.  This observer will therefore
conclude that .

Now, to conclude that another entity is conscious is, by definition, to conclude that the
consciousness exists *independent* of the observer.  My sense of consciousness
does not depend on any other .  So if one observer is correct in concluding
that the iron bar is conscious, *all other observers must agree as well*.  So
even if , the fact that *some* observer could have encoded a Turing machine
that does produce consciousness means that you need to conclude that the bar is
conscious as well.

And of course there is nothing special about the iron bar.  We can encode bits
into physical matter any which way we choose.  The .

## But computers can still be conscious!

Now I want to be quite clear about the position I am arguing for.  By saying
that consciousness is not computation, I am *not* claiming that computers are
not or can never be conscious.  We could imagine a world in which consciousness
is produced by electric fields that fluctuate in the right patterns.  Perhaps,
in such a world, a digital computer running `consciousness.py` produces the
right patterns just as the neurons in the brain do.

But in this world, consciousness is a *physical* phenomenon, not a purely
computational phenomenon.  Computation may be necessary to produce
consciousness, but my claim is that it cannot be sufficient.  I can run
`consciousness.py` on a digital computer and produce a conscious being, but if
I run the same program on the "rocks in a desert" computer, I will not.
Consciousness is then hardware-dependent.  If consciousness were a purely
computational phenomenon, this would not be possible.  Any machine that runs
the same computation would produce the same phenomenon.

## Syntax is not semantics

The argument that computation is not consciousness can be summed up in a single
slogan: syntax is not semantics.  All computers can do is shuffle lumps of
matter around, whether that be rocks in a vast desert, or states of voltage .
But these lumps of matter have no intrinsic meaning.  The only reason we call a
box with a CPU in it a "computer" is because the operation of the voltages of
different parts of the CPU happen to map onto logical operations which we have
defined.  But there is no meaning to that apart from what we, as external
observers, have imposed on it.

A more intuitive way to put this is that a simulation of a brain cannot produce
consciousness any more than a simulation of the weather can produce rain.

## So what is consciousness then?

The idea that consciousness comes from computing a particular kind of program
is seductive because it seems to lay out a path towards understanding where
consciousness comes from.  If only we could write a clever enough computer
program, we could figure it out.

But if consciousness is not computation, then what is it?  This, of course, is
perhaps the hardest problem there is.  I don't claim to have the answer to this
question, but I think there are a few properties of consciousness that can at
least point the way to something resembling an answer.

### Consciousness is in the brain

### Consciousness is unitary

The second important property of consciousness that any theory needs to explain
is that consciousness is a single, individual experience.  My consciousness is
of my entire self.  It is not of half of myself, nor is it of some
superposition of you and me.  Somehow, whatever is going on in my brain to
produce my consciousness is limited to just my brain, but also includes my
*entire* brain.

Some individuals with severe epilepsy have to have the corpus callosum severed.
The corpus callosum joins the left hemisphere to the right hemisphere.  Once
these individuals have the corpus callosum severed, they seem to exhibit having
*two* consciousnesses rather than one.  

Could it be that 

### New biology or new physics



I have to admit that I am somewhat partial to Roger Penrose's idea that
consciousness has its origins in some kind of quantum mechanical phenomenon.
The main advantage of this idea is that entanglement is a physical mechanism
that unifies multiple objects separated across space in a deep way.  We could
imagine that somehow different parts of the brain produce states which are
entangled with each other   

But I will concede that this is nevertheless a far-fetched idea just because the
brain is a warm and noisy environment.  Entanglement, at least in any form that
we know of, is too delicate a state to be maintained in the brain for any
length of time.

[^1]:
    Strictly speaking, "qualia" refers to individual conscious experiences ---
    the sensation of hearing a bell, for example --- whereas consciousness is
    the unified collection of all qualia that a conscious being experiences. In
    fact this makes the problem of consciousness harder than qualia on its own,
    becaues a theory of consciousness needs to explain not only individual
    perception experiences, but how a collection of these experiences across
    space and time can be unified into single, coherent experience of being.

[^2]:
    Some algorithms can be exponenitally faster if they are run on a quantum
    computer than if they are run on a Turing machine (which is inherently
    classical).  Nevertheless, for our purposes the algorithmic efficiency
    isn't relevant.  The Turing machine can still compute the algorithm which
    is all that matters to us.

[^3]:
    This happens more frequently than you might think.  You can actually run an
    app on your smartphone that uses the camera as a cosmic ray detector.

[^4]:
    If we like we can tighten the definition such that the machine must not
    only produce identical outputs to the Turing machine, but must maintain
    identical internal states as well.  This makes no difference to the
    argument.

[^5]:
    This is the so-called "systems response" to John Searle's Chinese Room
    argument, though presented in an oblique way.  The argument is that while
    the rocks themselves might not be conscious, the whole *system* of the
    rocks being manipulated *is* conscious.  In Searle's thought experiment the
    computation being performed was an individual in a room manipulating
    symbols according to rules in a book rather than rocks in a desert, but the
    underlying idea is the same.
